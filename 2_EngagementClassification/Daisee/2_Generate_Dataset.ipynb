{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from Supports.ML.Auxiliary_ML_Experiment import create_data_window\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pathfolder_labels = \"New_matching_folder\"\n",
    "pathfolder_experiments = \"/Users/federicoimpellizzeri/PycharmProjects/Impellizzeri_IntelligentInterfaces/1_FER_Experiments/experiment_video_DAiSEE/Results_Experiment_FER_DAiSEE\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "pathname_folder_results = \"Datasets_Generated/\"\n",
    "\n",
    "folder_FER_results = \"FER_Daisee\"\n",
    "\n",
    "folder_FER_results_window = \"FER_Daisee_window\"\n",
    "folderpath_FER_results_window = os.path.join(pathname_folder_results, folder_FER_results_window)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "os.makedirs(pathname_folder_results, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dataset for Test set...\n",
      "(1415, 11, 7) (1415, 1, 4)\n",
      "Create dataset for Train set...\n",
      "(5335, 11, 7) (5335, 1, 4)\n",
      "Create dataset for Validation set...\n",
      "(1415, 11, 7) (1415, 1, 4)\n",
      "Create fully completed dataset...\n",
      " (8165, 11, 7) (8165, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "pathfolder_FER_results_daisee = os.path.join(pathname_folder_results, folder_FER_results)\n",
    "if not os.path.isdir(pathfolder_FER_results_daisee):\n",
    "    os.makedirs(pathfolder_FER_results_daisee, exist_ok=True)\n",
    "    X_full, y_full = [], []\n",
    "    for each_set in os.listdir(pathfolder_experiments):\n",
    "        if not each_set.endswith(\"DS_Store\"):\n",
    "            print(\"Create dataset for {} set...\".format(each_set))\n",
    "            X, y = [], []\n",
    "            df_label = pd.read_csv(os.path.join(pathfolder_labels, each_set+\"Labels.csv\"))\n",
    "            # print(df_label.shape)\n",
    "            names = np.array(df_label[['ClipID']], dtype=str)\n",
    "            folderpath_FER_results_single_set = os.path.join(pathfolder_experiments, each_set)\n",
    "            for each_sample in os.listdir(folderpath_FER_results_single_set):\n",
    "                if each_sample in names:\n",
    "                    if not each_sample.endswith(\"DS_Store\"):\n",
    "                        df_sample = pd.read_csv(os.path.join(pathfolder_experiments, each_set, each_sample, 'report_experiment.csv'))\n",
    "                        seq_emotions = df_sample['high_emotion'].to_numpy(dtype=str)\n",
    "                        if not all(x == \"face_not_detected\" for x in seq_emotions):\n",
    "                            df_sample = df_sample.to_numpy()[:,4:-1]\n",
    "                            mm_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "                            df_sample_scaled = mm_scaler.fit_transform(X=df_sample)\n",
    "                            labels = df_label.loc[df_label['ClipID'] == int(each_sample)].values[:,1:]\n",
    "                            X.append(df_sample_scaled)\n",
    "                            X_full.append(df_sample_scaled)\n",
    "                            y.append(labels)\n",
    "                            y_full.append(labels)\n",
    "            X, y = np.array(X), np.array(y)\n",
    "            print(X.shape, y.shape)\n",
    "            pathfolder_set = os.path.join(pathfolder_FER_results_daisee,each_set)\n",
    "            name_X, name_Y = \"X_\"+each_set+\".npy\", \"y_\"+each_set+\".npy\"\n",
    "            os.makedirs(pathfolder_set, exist_ok=True)\n",
    "            path_X = os.path.join(pathfolder_set, name_X)\n",
    "            path_Y = os.path.join(pathfolder_set, name_Y)\n",
    "            np.save(file=path_X, arr=X)\n",
    "            np.save(file=path_Y, arr=y)\n",
    "    path_folder_fullset = os.path.join(pathfolder_FER_results_daisee, \"All\")\n",
    "    os.makedirs(path_folder_fullset, exist_ok=True)\n",
    "    path_X_full = os.path.join(path_folder_fullset, \"X_All.npy\")\n",
    "    path_Y_full = os.path.join(path_folder_fullset, \"y_All.npy\")\n",
    "    X_full, y_full = np.array(X_full), np.array(y_full)\n",
    "    print(\"Create fully completed dataset...\\n\",X_full.shape, y_full.shape)\n",
    "    np.save(file=path_X_full, arr=X_full)\n",
    "    np.save(file=path_Y_full, arr=y_full)\n",
    "else:\n",
    "    print(\"Datasets already created!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "list_of_windows = [3 ,5, 7, 9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of dataset for window-size equals to 3...\n",
      "Window-size: 3 for Test set...\n",
      "(12735, 3, 7) (12735, 1, 4)\n",
      "Window-size: 3 for All set...\n",
      "(73485, 3, 7) (73485, 1, 4)\n",
      "Window-size: 3 for Train set...\n",
      "(48015, 3, 7) (48015, 1, 4)\n",
      "Window-size: 3 for Validation set...\n",
      "(12735, 3, 7) (12735, 1, 4)\n",
      "Creation of dataset for window-size equals to 5...\n",
      "Window-size: 5 for Test set...\n",
      "(9905, 5, 7) (9905, 1, 4)\n",
      "Window-size: 5 for All set...\n",
      "(57155, 5, 7) (57155, 1, 4)\n",
      "Window-size: 5 for Train set...\n",
      "(37345, 5, 7) (37345, 1, 4)\n",
      "Window-size: 5 for Validation set...\n",
      "(9905, 5, 7) (9905, 1, 4)\n",
      "Creation of dataset for window-size equals to 7...\n",
      "Window-size: 7 for Test set...\n",
      "(7075, 7, 7) (7075, 1, 4)\n",
      "Window-size: 7 for All set...\n",
      "(40825, 7, 7) (40825, 1, 4)\n",
      "Window-size: 7 for Train set...\n",
      "(26675, 7, 7) (26675, 1, 4)\n",
      "Window-size: 7 for Validation set...\n",
      "(7075, 7, 7) (7075, 1, 4)\n",
      "Creation of dataset for window-size equals to 9...\n",
      "Window-size: 9 for Test set...\n",
      "(4245, 9, 7) (4245, 1, 4)\n",
      "Window-size: 9 for All set...\n",
      "(24495, 9, 7) (24495, 1, 4)\n",
      "Window-size: 9 for Train set...\n",
      "(16005, 9, 7) (16005, 1, 4)\n",
      "Window-size: 9 for Validation set...\n",
      "(4245, 9, 7) (4245, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(folderpath_FER_results_window, exist_ok=True)\n",
    "for w in list_of_windows:\n",
    "    name_folder = \"window_\"+str(w)\n",
    "    pathfolder_results_windows = os.path.join(folderpath_FER_results_window,name_folder)\n",
    "    if not os.path.isdir(pathfolder_results_windows):\n",
    "        print(\"Creation of dataset for window-size equals to {}...\".format(w))\n",
    "        os.makedirs(pathfolder_results_windows, exist_ok=True)\n",
    "        for each_set in os.listdir(pathfolder_FER_results_daisee):\n",
    "            pathfolder_set = os.path.join(pathfolder_results_windows, each_set)\n",
    "            os.makedirs(pathfolder_set, exist_ok=True)\n",
    "            print(\"Window-size: {} for {} set...\".format(w, each_set))\n",
    "            pathfile_name_set = os.path.join(pathfolder_FER_results_daisee, each_set)\n",
    "            name_X, name_y = \"X_\"+each_set+\".npy\", \"y_\"+each_set+\".npy\"\n",
    "            path_array_X = os.path.join(pathfile_name_set, name_X)\n",
    "            path_array_y = os.path.join(pathfile_name_set, name_y)\n",
    "            array_X, array_y = np.load(path_array_X), np.load(path_array_y)\n",
    "            X_windowed, y_windowed = create_data_window(data=array_X, set_label=array_y, window=w)\n",
    "            print(X_windowed.shape, y_windowed.shape)\n",
    "            name_X_windowed, name_y_windowed = \"X_\"+each_set+\"_window_\"+str(w)+\".npy\", \"y_\"+each_set+\"_window_\"+str(w)+\".npy\"\n",
    "            path_array_windowed_X = os.path.join(pathfolder_set, name_X_windowed)\n",
    "            path_array_windowed_y = os.path.join(pathfolder_set, name_y_windowed)\n",
    "            np.save(file=path_array_windowed_X, arr=X_windowed)\n",
    "            np.save(file=path_array_windowed_y, arr=y_windowed)\n",
    "    else:\n",
    "        print(\"Already exists folder with window-size equals to {}!\".format(w))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}